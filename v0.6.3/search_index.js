var documenterSearchIndex = {"docs":
[{"location":"sdi/#SDI","page":"SDI","title":"SDI","text":"","category":"section"},{"location":"sdi/","page":"SDI","title":"SDI","text":"warning: Warning\nSDI should be considered very experimental.","category":"page"},{"location":"sdi/","page":"SDI","title":"SDI","text":"ADI.SDIAlgorithm","category":"page"},{"location":"sdi/#ADI.SDIAlgorithm","page":"SDI","title":"ADI.SDIAlgorithm","text":"ADI.SDIAlgorithm <: ADI.ADIAlgorithm\n\nSpectral differential imaging (SDI) algorithms. These work on 4-D SDI tensors. To use these algorithms, simply treat them like functions (or call process)\n\n(::SDIAlgorithm)(data::AbstractArray{T,4}, angles, scales; [ref] kwargs...)\n\nThe data is expected to be laid out in (nλ, nf, ny, nx) format, so you may need to permutedims before processing the data. The scales correspond to the relative wavelength scales for each spectrum, and can be retrieved with HCIToolbox.scale_list.\n\nAlgorithms\n\nThe current SDI implementations are\n\nSingleSDI\nDoubleSDI\nSliceSDI\n\n\n\n\n\n","category":"type"},{"location":"sdi/#API/Reference","page":"SDI","title":"API/Reference","text":"","category":"section"},{"location":"sdi/","page":"SDI","title":"SDI","text":"SingleSDI\nDoubleSDI\nSliceSDI\nscale_list","category":"page"},{"location":"sdi/#ADI.SingleSDI","page":"SDI","title":"ADI.SingleSDI","text":"SingleSDI(alg)\n\nA wrapper algorithm for spectral differential imaging (SDI) data reduced in a single pass. This means that each channel will be scaled and then concatenated together, so an SDI tensor (nλ, nf, y, x) becomes a stack (nλ * nf, y, x) which is processed by the underlying alg like ADI data.\n\ntip: Tip\nSingleSDI is the default SDI mode. This means instead of writingSingleSDI(PCA(15))(data, angles, scales)you can just writePCA(15)(data, angles, scales)\n\n\n\n\n\n","category":"type"},{"location":"sdi/#ADI.DoubleSDI","page":"SDI","title":"ADI.DoubleSDI","text":"DoubleSDI(alg)\nDoubleSDI(alg_spec, alg_temp)\n\nA wrapper algorithm for spectral differential imaging (SDI) data reduced in two passes. The first pass uses alg_spec to reduce each spectral cube slice in the SDI tensor. Then, the spectral residual frames will be reduced using alg_temp, which will include the derotation and final combination.\n\nThe difference between DoubleSDI and SliceSDI is that DoubleSDI does its first pass in the spectral slice, effectively collapsing the slice before performing ADI on the residual cube. SliceSDI does its first pass in the temporal slice, collapsing it first before performing ADI on the residual cube.\n\nExamples\n\njulia> data, angles, scales = # load data...\n\n# Median subtraction for each spectral slice,\n# GreeDS{PCA} subtraction on spectral residual cube\njulia> res = DoubleSDI(Classic(), GreeDS(15))(data, angles, scales)\n\n\n\n\n\n","category":"type"},{"location":"sdi/#ADI.SliceSDI","page":"SDI","title":"ADI.SliceSDI","text":"SliceSDI(alg)\nSliceSDI(alg_spec, alg_temp)\n\nA wrapper algorithm for spectral differential imaging (SDI) data reduced in two passes. The first pass uses alg_temp to reduce each temporal cube slice in the SDI tensor. These residuals will be rescaled and stacked into a new cube. Then, the temporal residual frames will be reduced using alg_spec, which will include the derotation and final combination.\n\nThe difference between SliceSDI and DoubleSDI is that DoubleSDI does its first pass in the spectral slice, effectively collapsing the slice before performing ADI on the residual cube. SliceSDI does its first pass in the temporal slice, collapsing it first before performing ADI on the residual cube.\n\nExamples\n\njulia> data, angles, scales = # load data...\n\n# Median subtraction for each spectral slice,\n# GreeDS{PCA} subtraction on spectral residual cube\njulia> res = SliceSDI(Classic(), GreeDS(15))(data, angles, scales)\n\n\n\n\n\n","category":"type"},{"location":"sdi/#HCIToolbox.scale_list","page":"SDI","title":"HCIToolbox.scale_list","text":"scale_list(wavelengths)\n\nReturns a list of scaling factors for aligning SDI tensors from a list of wavelengths.\n\n\n\n\n\n","category":"function"},{"location":"benchmarks/#Benchmarks","page":"Benchmarks","title":"Benchmarks","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"The large scale image-processing required for ADI algorithms can lead to concerns about runtime efficiency. To this end, ADI.jl (and the associated JuliaHCI packages) are developed with performance in mind. These packages do not aim to be as fast as possible; rather they focus on being as fast as is convenient (for the users and the devs).","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"The Vortex Imaging Pipeline (VIP) is the inspiration for ADI.jl. It is one of the major Python HCI packages and it offers many more features than ADI.jl. Some of the common uses for both packages include full-frame ADI processing, S/N maps, and contrast curves.","category":"page"},{"location":"benchmarks/#System/Setup-Information","page":"Benchmarks","title":"System/Setup Information","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"The benchmarks here can be found in the bench/ folder organized into Julia files. The benchmarks utilize BenchmarkTools.jl, PyCall.jl with virtualenv, and CSV.jl for accuracy, reproducibility, and organization.","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Julia Version 1.6.0-beta1\nCommit b84990e1ac* (2021-01-08 12:42 UTC)\nPlatform Info:\n  OS: macOS (x86_64-apple-darwin19.6.0)\n  CPU: Intel(R) Core(TM) i5-8259U CPU @ 2.30GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.0 (ORCJIT, skylake)\nEnvironment:\n  JULIA_NUM_THREADS = 4","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"For the python code, there is a requirements.txt file in bench/. To reproduce this environment, (optionally) activate a virtual environment then install from the requirements file.","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"(venv) $ pip install -r requirements.txt","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"For reproducibility, there is a Manifest.toml file in bench/. To reproduce this environment, first activate it, then instantiate it","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"$ julia --project=bench -e 'using Pkg; Pkg.instantiate()'","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"warning: PyCall.jl and virtual environments\nThe interface between Julia and python is handled by PyCall.jl. When using a virtual environment, PyCall may not use the correct python library. Before running the benchmarks, please read this reference.","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"tip: Multi-threading\nSome of the image-processing methods in ADI.jl and HCIToolbox.jl are multi-threaded, and will lead to a noticable difference in some benchmarks. To take advantage of this, set the environment variable JULIA_NUM_THREADS before starting your runtime. Multi-Threading documentation.","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"using CSV\nusing DataFrames\nusing StatsPlots\nbenchdir(args...) = joinpath(\"..\", \"..\" ,\"bench\", args...);","category":"page"},{"location":"benchmarks/#ADI-Reduction","page":"Benchmarks","title":"ADI Reduction","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"These benchmarks show the duration to fully reduce ADI data for various algorithms. The data used are beta Pictoris and HR8799 from HCIDatasets.jl.","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"adi_data = CSV.File(benchdir(\"adi_benchmarks.csv\")) |> DataFrame |> sort!\ncube_labels = @. ifelse(adi_data.N == 622261, \"Beta Pictoris\", \"HR8799\")\ninsertcols!(adi_data, 4, :cube => cube_labels)\nadi_groups = groupby(adi_data, :framework)","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"cube_groups = groupby(adi_data, :cube)\nplot(\n    @df(cube_groups[1], groupedbar(:alg, :time, group=:framework, yscale=:log10)),\n    @df(cube_groups[2], groupedbar(:alg, :time, group=:framework)),\n    size=(700, 350),\n    leg=:topleft,\n    ylabel=\"time (s)\",\n    title=[\"Beta Pictoris\" \"HR8799\"]\n)","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Please note the log-scale for the left figure.","category":"page"},{"location":"benchmarks/#Detection-Maps","page":"Benchmarks","title":"Detection Maps","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"This benchmark measures the duration to produce a signal-to-noise ratio (S/N) map. Rather than test exact cubes, these benchmarks test randomly generated frames of various sizes. The FWHM is fixed at 5.","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"snrmap_data = CSV.File(benchdir(\"snrmap_benchmarks.csv\")) |> DataFrame |> sort!\nsnrmap_groups = groupby(snrmap_data, :framework)","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"@df snrmap_data scatter(\n    :N,\n    :time,\n    group=:framework,\n    ms=6,\n    xlabel=\"number of pixels\",\n    ylabel=\"time (s)\"\n)","category":"page"},{"location":"benchmarks/#Contrast-Curves","page":"Benchmarks","title":"Contrast Curves","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Finally, this benchmark measures the duration to generate a contrast curve for analyzing the algorithmic throughput of an ADI algorithm. For both benchmarks 3 azimuthal branches are used for throughput injections and a FWHM of 8. A Gaussian PSF function is evaluated in a (21, 21) grid for the injections. The data used are beta Pictoris and HR8799 from HCIDatasets.jl.","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"contrast_data = CSV.File(benchdir(\"contrast_benchmarks.csv\")) |> DataFrame |> sort!\ncube_labels = @. ifelse(contrast_data.N == 622261, \"Beta Pictoris\", \"HR8799\")\ninsertcols!(contrast_data, 4, :cube => cube_labels)\ncontrast_groups = groupby(contrast_data, :framework)","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"@df contrast_data groupedbar(\n    :cube,\n    :time,\n    group=:framework,\n    leg=:topleft,\n    ylabel=\"time (s)\",\n    yscale=:log10,\n)","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Please note the log-scale.","category":"page"},{"location":"algorithms/nmf/#nmf","page":"NMF","title":"NMF","text":"","category":"section"},{"location":"algorithms/nmf/#API/Reference","page":"NMF","title":"API/Reference","text":"","category":"section"},{"location":"algorithms/nmf/","page":"NMF","title":"NMF","text":"NMF","category":"page"},{"location":"algorithms/nmf/#ADI.NMF","page":"NMF","title":"ADI.NMF","text":"NMF(;ncomps=nothing)\nNMF(ncomps)\n\nUse non-negative matrix factorization (NMF, NNMF) to form a non-negative, low-rank, and orthonormal basis of the input. The implementation of the underlying NMF is provided by NMF.jl. The implementation uses a non-negative SVD for initialization and a coordinate-descent solver to fit.\n\nIf ncomps is nothing, it will be set to the number of frames in the reference cube when processed.\n\nwarning: Non-negativity constraint\nNMF is not designed to fit negative values. This algorithm will warn you (but will not error) if a target or reference cube contains negative values. The output may seem reasonable, but it is not well-defined with respect to the NMF algorithm. To overcome this, rescaling the data by its minimum before processing is necessarytarget = cube .- minimum(cube)\nS = reconstruct(NMF(), target, angles)When doing full-frame reduction (e.g. NMF()(cube, angles)) this is handled automatically, so this constraint only applies to the lower-level API and methods which rely on those, such as GreeDS. In general, if you see warnings, heed them.\n\nReferences\n\nRen et al. 2018 Non-negative Matrix Factorization: Robust Extraction of Extended Structures\n\n\n\n\n\n","category":"type"},{"location":"algorithms/pca/#pca","page":"PCA","title":"PCA","text":"","category":"section"},{"location":"algorithms/pca/#API/Reference","page":"PCA","title":"API/Reference","text":"","category":"section"},{"location":"algorithms/pca/","page":"PCA","title":"PCA","text":"PCA\nTPCA","category":"page"},{"location":"algorithms/pca/#ADI.PCA","page":"PCA","title":"ADI.PCA","text":"PCA(ncomps; options...)\nPCA(;ncomps=nothing, options...)\n\nUse principal components analysis (PCA) to form a low-rank orthonormal basis of the input. Uses deterministic singular-value decomposition (SVD) to decompose data.\n\nIf ncomps is nothing, the basis will not be truncated (i.e. ncomps is equal to the number of frames). ncomps can be set to :noise or :pratio to automatically choose the number of components using the residual frame noise or principal ratio, respectively. For more information, see the extended help.\n\nReferences\n\nSoummer, Pueyo, and Larkin (2012) \"Detection and Characterization of Exoplanets and Disks Using Projections on Karhunen-Loève Eigenimages\"\n\nExtended help\n\nOptimizing ncomps\n\nThere are a few ways to optimize ncomps using the input data. Additional options for the optimization are listed below\n\nncomps=:noise - residual noise optimization\nncomps=:pratio - principal ratio optimization\n\nResidual noise optimization\n\nThis technique progressively increases ncomps at each step measuring the pixel-to-pixel noise (standard deviation) in the residual data. Iteration will stop when the noise is not improving beyond a threshold. This is suited for data with similar statistical characteristics, such as an annulus more so than a full-frame cube.\n\ncollapse=false - if true, the temporal median of the residual data will be used for measuring the noise.\nnoise_error=1e-3 - the threshold for the minimal noise improvement looking back 2 iterations\n\nPrincipal ratio optimization\n\nThis technique chooses the number of components required to explain some ratio of the total variance in the data. This is known as the principal ratio or the explained variance ratio. The explained variance is measured by transforming the singular values of the SVD decomposition (Λ = @. S^2 / (n - 1)).\n\npratio=0.9 - the target principal ratio (between 0 and 1)\n\n\n\n\n\n","category":"type"},{"location":"algorithms/pca/#ADI.TPCA","page":"PCA","title":"ADI.TPCA","text":"TPCA(;ncomps=nothing, options...)\nTPCA(ncomps; options...)\n\nPerform principal components analysis (PCA) using truncated SVD (TSVD; provided by TSVD.jl) instead of deterministic SVD. This is often faster than PCA but is non-deterministic, so the results may be different. See the PCA docstring for more information about the options.\n\nSee Also\n\nPCA, TSVD.tsvd\n\n\n\n\n\n","category":"type"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"EditURL = \"https://github.com/JuliaHCI/ADI.jl/blob/master/examples/geometries.jl\"","category":"page"},{"location":"examples/geometries/#ex2","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"This example will walk through a more advanced reduction exploiting geometric and temporal filtering techniques.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"","category":"page"},{"location":"examples/geometries/#Setup","page":"Exploring spatial and temporal filtering","title":"Setup","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"Let's begin by importing the necessary libraries. You may need to add these packages if they are not already on your system.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"(@v1.5) pkg> add HCIDatasets Plots","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"In addition, a Project.toml file exists in the examples/ folder with the necessary dependencies. Start the REPL in the base ADI.jl folder, then from Pkg mode","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"(@v1.5) pkg> activate examples\n(examples) pkg> instantiate\njulia> include(\"examples/geometries.jl\")","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"using ADI\nusing HCIDatasets: HR8799\nusing Plots\n\n# set up plotting\nfunction imshow(img; kwargs...)\n    ylim = extrema(axes(img, 1))\n    xlim = extrema(axes(img, 2))\n    heatmap(axes(img)..., img; aspect_ratio=1, xlim=xlim, ylim=ylim, kwargs...)\nend;\nnothing #hide","category":"page"},{"location":"examples/geometries/#Initial-Reduction","page":"Exploring spatial and temporal filtering","title":"Initial Reduction","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"First, lets load the data and do some initial reductions","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"cube, angles = HR8799[:cube, :pa]\nfwhm = 8.2\n\nname = \"PCA(10) - Full Frame\"\nres = PCA(10)(cube, angles)\nresults = Dict(name => res)\nimshow(res, title=name)","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"The four companions (HR8799b,c,d, and e) should be evident in this residual.","category":"page"},{"location":"examples/geometries/#Geometric-Filtering","page":"Exploring spatial and temporal filtering","title":"Geometric Filtering","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"Geometric filtering is the process of using sub-region(s) in each frame to use as the target and reference libraries. Geometric filtering is useful to select pixels with similar noise distributions, such as an annulus, as well as to reduce the total number of pixels, increasing runtime performance.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"For our example, lets start by looking at annuli for each companion and optimizing the number of principal components. We can use AnnulusView to wrap cube and filter the input. AnnulusView works by calculating the indices for a single annulus and creates a view into cube with those indices. It does not copy any data, and let's us access only the pixels within the annulus.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"av = AnnulusView(cube; inner=31, outer=51)\nimshow(av[1, :, :], xlim=(198, 304), ylim=(198, 304))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"because this annulus should have similar noise characteristics, we can automatically choose the number of components by trying to minimize the noise in the residual frame. The algorithm will increase ncomps until the noise does not improve by at least noise_error.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"alg = PCA(:noise, noise_error=25)\nres_e = alg(av, angles)\nimshow(res_e, title=\"PCA - HR8799e\", xlim=(198, 304), ylim=(198, 304))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"av = AnnulusView(cube; inner=57, outer=77)\nres_d = alg(av, angles)\nimshow(res_d, title=\"PCA - HR8799d\", xlim=(170, 332), ylim=(170, 332))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"av = AnnulusView(cube; inner=86, outer=106)\nres_c = alg(av, angles)\nimshow(res_c, title=\"PCA - HR8799c\", xlim=(142, 360), ylim=(142, 360))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"av = AnnulusView(cube; inner=163, outer=183)\nres_b = alg(av, angles)\nimshow(res_b, title=\"PCA - HR8799b\", xlim=(57, 445), ylim=(57, 445))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"combined_res = sum([res_e, res_d, res_c, res_b])\nimshow(combined_res, title=\"PCA - Annular\", xlim=(57, 445), ylim=(57, 445))","category":"page"},{"location":"examples/geometries/#Handling-multiple-annuli","page":"Exploring spatial and temporal filtering","title":"Handling multiple annuli","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"Instead of doing each annulus by hand, we can use MultiAnnulusView to assemble the annuli","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"width = 20\nradii = [41, 67, 96, 173]\nmav = MultiAnnulusView(cube, width, radii);\nnothing #hide","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"res = alg(mav, angles)\n\nname = \"PCA(noise_error=25) - Annular\"\npush!(results, name => res)\nimshow(res, title=name, xlim=(57, 445), ylim=(57, 445))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"When reducing MultiAnnulusView, we can specify a separate algorithm for each annulus, and even combine that with Framewise","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"algs = [PCA(6), PCA(5), PCA(5), PCA(3)]\nres = process(algs, mav, angles)\n\nname = \"PCA([6, 5, 5, 3]) - Annular\"\npush!(results, name => res)\nimshow(res, title=name, xlim=(57, 445), ylim=(57, 445))","category":"page"},{"location":"examples/geometries/#Framewise-reduction-and-temporal-filtering","page":"Exploring spatial and temporal filtering","title":"Framewise reduction and temporal filtering","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"As pointed out in Marois et al. 2006, we can filter the reference data in the time domain by rejecting frames which have not rotated a sufficient amount. In order to enable this, we have to fit each frame in the target data cube separately, since we calculate the frames to reject for each of them. We call this process framewise reduction, which is enabled by wrapping an algorithm in Framewise.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"By default, Framewise will reject frames which have not rotated at least 1 FWHM, set by the delta_rot keyword argument.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"fr_alg = Framewise(algs, delta_rot=1)\nres = fr_alg(mav, angles; fwhm=fwhm)\n\nname = \"PCA([6, 5, 5, 3]) - Annular\\n(delta_rot=1)\"\npush!(results, name => res)\nimshow(res, title=name, xlim=(57, 445), ylim=(57, 445))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"According to Absil et al. 2013, a slightly better contrast can be reached for the innermost annuli if we consider a delta_rot as small as 0.1 FWHM. This is because at very small separation, the effect of speckle correlation is more significant than self-subtraction.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"We can set delta_rot as a tuple or vector to use varying parallactic angle thresholds for each annulus.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"fr_alg = Framewise(algs, delta_rot=(0.1, 1))\nres = fr_alg(mav, angles; fwhm=fwhm)\n\nname = \"PCA([6, 5, 5, 3]) - Annular\\n(delta_rot=(0.1, 1))\"\npush!(results, name => res)\nimshow(res, title=name, xlim=(57, 445), ylim=(57, 445))","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"We can also limit the number of frames used in the reference library, I.E. the k nearest frames. For example, to recreate the algorithm derived in § 5.2 of Marois et al. 2006, which uses the 4 closest frames (which have rotated at least 1.5 FWHM) to construct the reference library.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"# subtract median frame\nresid_cube = subtract(Classic(), cube)\n# form annuli\nmav = MultiAnnulusView(resid_cube, width, radii)\n# 1.5 FWHM rotation, keep closest 4 frames\nfr_alg = Framewise(Classic(), delta_rot=1.5, limit=4)\nres = fr_alg(mav, angles; fwhm=fwhm)\n\nname = \"Classic - Annular\\n(delta_rot=1.5, limit=4)\"\npush!(results, name => res)\nimshow(res, title=name, xlim=(57, 445), ylim=(57, 445))","category":"page"},{"location":"examples/geometries/#Gallery-of-results","page":"Exploring spatial and temporal filtering","title":"Gallery of results","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"p = plot(layout=(2, 3), ticks=false, xlim=(57, 445), ylim=(57, 445),\n        aspect_ratio=1, size=(800, 400), titlefontsize=9)\nfor (i, (name, res)) in enumerate(results)\n    heatmap!(res; title=name, sp=i)\nend\np #hide","category":"page"},{"location":"examples/geometries/#S/N-maps","page":"Exploring spatial and temporal filtering","title":"S/N maps","text":"","category":"section"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"For comparing reductions, we'll use signal-to-noise ratio (S/N, SNR) of the residual frame. All the frames below are shown on the same color scale, from S/N=0 to 13.","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"p = plot(layout=(2, 3), size=(800, 550), clim=(0, 13),\n        cbar=false, ticks=false, aspect_ratio=1, xlim=(57, 445),\n        ylim=(57, 445), titlefontsize=9)\nfor (i, (name, res)) in enumerate(results)\n    sn = detectionmap(res, fwhm)\n    heatmap!(sn; title=name, sp=i)\nend\np #hide","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"","category":"page"},{"location":"examples/geometries/","page":"Exploring spatial and temporal filtering","title":"Exploring spatial and temporal filtering","text":"This page was generated using Literate.jl.","category":"page"},{"location":"gettingstarted/#gettingstarted","page":"Getting Started with ADI.jl","title":"Getting Started","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Here is a quick-start guide for people familiar with ADI and experience using tools like VIP or pyKLIP. For installation and setup information, see the Installation and Setup section.","category":"page"},{"location":"gettingstarted/#Expected-Data-Formats","page":"Getting Started with ADI.jl","title":"Expected Data Formats","text":"","category":"section"},{"location":"gettingstarted/#ADI-Cube","page":"Getting Started with ADI.jl","title":"ADI Cube","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"For standard ADI data, we store the values in a 3-dimensional array, where the first dimension is temporal, and the remaining dimensions are pixel coordinates. This is how most ADI data are stored on disk (typically in FITS files) and allow specifying operations like a tensor. This cube should already be registered with the star in the center of the frames (note the center is only well-defined for odd-sized frames, even though even-sized frames will work fine).","category":"page"},{"location":"gettingstarted/#Parallactic-Angles","page":"Getting Started with ADI.jl","title":"Parallactic Angles","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"The parallactic angles should be stored as degrees in a vector. The parallactic angle X[i] will result in rotating frame i X[i] degrees counter-clockwise.","category":"page"},{"location":"gettingstarted/#SDI-Cube/Tensor","page":"Getting Started with ADI.jl","title":"SDI Cube/Tensor","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"For standard SDI data, we store the values in a 4-dimensional array, where the first dimension is spectral, the second is temporal, and the remaining dimensions are pixel coordinates. This is how some SDI data are stored on disk (typically in FITS files) and allow specifying operations like a tensor. For SDI data that is stored with the temporal axis first, the dimensions should be permuted before processing (see permutedims). This cube should also be registered with the star in the center of the frame.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"In addition to the SDI tensor and parallactic angles, the list of wavelengths are required (for scaling speckles) and a spectral template can be used. To create a scale list from the wavelengths, use scale_list. Currently there is not support for spectral templates.","category":"page"},{"location":"gettingstarted/#Algorithms","page":"Getting Started with ADI.jl","title":"Algorithms","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"The following algorithms are implemented:","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Classic Subtraction\nPCA\nNMF\nGreeDS","category":"page"},{"location":"gettingstarted/#Processing-Patterns","page":"Getting Started with ADI.jl","title":"Processing Patterns","text":"","category":"section"},{"location":"gettingstarted/#Full-Frame-ADI-Reduction","page":"Getting Started with ADI.jl","title":"Full Frame ADI Reduction","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Given an algorithm alg, we can fully process ADI data by calling alg like a function, or using the process method","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"julia> using ADI\n\njulia> alg = PCA(ncomps=5)\n\njulia> resid = alg(cube, angles)\n\njulia> resid === process(alg, cube, angles)\ntrue","category":"page"},{"location":"gettingstarted/#Full-Frame-RDI-Reduction","page":"Getting Started with ADI.jl","title":"Full Frame RDI Reduction","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"The only difference here is the inclusion of a reference cube.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"julia> alg = PCA(ncomps=5)\n\njulia> resid = alg(cube, angles; ref=cube_ref)","category":"page"},{"location":"gettingstarted/#Reduction-Process","page":"Getting Started with ADI.jl","title":"Reduction Process","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"The process for producing the flat, residual frame follows this general workflow","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Create a cube of the speckle approximation, S\nSubtract S from the data cube to create the residual cube R\nDerotate R frame-by-frame according to the parallactic angle\nCollapse the derotated R","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"In ADI.jl this process looks like this:","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"cube, angles = # load data\nS = reconstruct(PCA(10), cube)\nR = cube .- S\nR_derotate = derotate(R, angles)\nresid = collapse(R_derotate)\n\n# or, more succinctly\nR = subtract(PCA(10), cube)\nresid = collapse(R, angles)","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Notice how the only part of this specific to the algorithm is reconstruct? This lets us have the super-compact functional form from above without having to copy the common code for each algorithm.","category":"page"},{"location":"gettingstarted/#Altering-the-Geometry","page":"Getting Started with ADI.jl","title":"Altering the Geometry","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"HCIToolbox.jl has utilities for geometrically filtering the input data, such as only taking an annulus of the input cube or iterating over many annuli. This is exactly the purpose of AnnulusView and MultiAnnulusView, which use indexing tricks to retrieve the pixels only within the spatial region of interest without having to copy the input data.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"If you wrap a cube in one of these views, ADI.jl will handle it automatically (if the algorithm supports it). Since these views filter the pixels, the runtime performance will generally be faster than the full-frame equivalents.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"ann = AnnulusView(cube; inner=15, outer=25)\nres = PCA(10)(ann, angles)","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"# annuli of width 5 starting at 5 pixels and ending at the edge of the cube\nanns = MultiAnnulusView(cube, 5; inner=5)\nres = PCA(10)(anns, angles)\n\n# use different algorithms for each annulus\nN_ann = length(anns.indices)\nalgs = [PCA(10), PCA(9), PCA(8), ...]\nres = process(algs, anns, angles)","category":"page"},{"location":"gettingstarted/#Comparison-to-VIP","page":"Getting Started with ADI.jl","title":"Comparison to VIP","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"ADI.jl took a lot of ideas from VIP and expanded them using the power of Julia. To begin with, Julia typically has smaller and more self-contained packages, so most of the basic image-processing that is used here is actually written in the HCIToolbox.jl package. In the future, I have plans to incorporate forward-modeling distributions in Firefly.jl, which currently is an active research project.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Some technical distinctions to VIP","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Julia is 1-indexed. This means all the positions for apertures, bounds, images, etc. start at 1. This is distinct from 0-based indexing in python, but is equivalent to the indexing in DS9 and IRAF.\nJulia's std uses the sample statistic (n-1 degrees of freedom) while numpy's std uses the population statistic (n degrees of freedom). This may cause very slight differences in measurements that rely on this.\nAperture mapping - many of the Metrics are derived by measuring statistics in an annulus of apertures. In VIP, this ring is not equally distributed- the angle between apertures is based on the exact number of apertures rather than the integral number of apertures that are actually measured. In ADI.jl the angle between apertures is evenly distributed. The same number of pixels are discarded in both packages, but in VIP they all end up in the same region of the image (see this figure).\nCollapsing - by default VIP collapses a cube by derotating it then finding the median frame. In ADI.jl, the default collapse method is a weighted sum using the inverse of the temporal variance for weighting. This is documented in HCIToolbox.collapse and can be overridden by passing the keyword argument method=median or whichever statistical funciton you want to use.\nImage interpolation - by default VIP uses a lanczos4 interpolator from opencv, by default ADI.jl uses a bilinear b-spline interpolator through Interpolations.jl\nAnnular and framewise processing - some of the VIP algorithms allow you to go annulus-by-annulus and optionally filter the frames using parallactic angle thresholds. ADI.jl does not bake these options in using keyword arguments; instead, the geometric filtering is achieved through AnnulusView and MultiAnnulusView. Parallactic angle thresholding is implemented in the Framewise algorithm wrapper. I've separated these techniques because they are fundamentally independent and because it greatly increases the composability of the algorithms.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"The biggest difference, though, is Julia's multiple-dispatch system and how that allows ADI.jl to do more with less code. For example, the GreeDS algorithm was designed explicitly for PCA, but the formalism of it is more generic than that. Rather than hard-coding in PCA, the GreeDS algorithm was written generically, and Julia's multiple-dispatch  allows the use of, say, NMF instead of PCA. By making the code generic and modular, ADI.jl enables rapid experimentation with different post-processing algorithms and techniques as well as minimizing the code required to implement a new algorithm and be able to fully use the ADI.jl API.","category":"page"},{"location":"gettingstarted/#Feature-comparison","page":"Getting Started with ADI.jl","title":"Feature comparison","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Some notable libraries for HCI tasks include VIP, pyKLIP, and PynPoint. A table of the feature sets of these packages alongside ADI.jl is presented below. In general VIP offers the most diversity in algorithms and their applications, but not all algorithms are as feature-complete as the PCA implementation. VIP also contains many useful utilities for pre-processing and a pipeline framework. pyKLIP primarily uses the PCA (KLIP) algorithm, but offers many forward modeling implementations. PynPoint has a highly modular pre-processing module that is focused on pipelines.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"- Pre. Algs. Techs. D.M. F.M.\nADI.jl ✗ median, PCA, NMF, fixed-point GreeDS Full-frame ADI/RDI, SDI (experimental), annular ADI* detection maps, STIM, SLIMask, contrast curve ✗\nVIP ✓ median, LOCI, PCA, NMF, LLSG, ANDROMEDA, pairwise frame differencing Full-frame ADI/RDI, SDI, annular ADI/RDI* detection maps, blob detection, STIM, ROC, contrast curve NegFC\npyKLIP ✗ PCA, NMF, weighted PCA Full-frame ADI/RDI, SDI, annular ADI/RDI detection maps, blob detection, contrast curve, cross-correlation KLIP-FM, Planet Evidence, matched filter (FMMF), spectrum fitting, DiskFM\nPynPoint ✓ median, PCA Full-frame ADI/RDI, SDI detection maps, contrast curve ✗","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Column labels: Pre-processing, Algorithms, Techniques, Detection Metrics, Forward Modeling.","category":"page"},{"location":"gettingstarted/","page":"Getting Started with ADI.jl","title":"Getting Started with ADI.jl","text":"Techniques marked with * indicate partial support, meaning that not all algorithms are supported.","category":"page"},{"location":"algorithms/api/#API/Reference","page":"API/Reference","title":"API/Reference","text":"","category":"section"},{"location":"algorithms/api/","page":"API/Reference","title":"API/Reference","text":"Pages = [\"algorithms/api.md\",\n         \"algorithms/classic.md\",\n         \"algorithms/greeds.md\",\n         \"algorithms/nmf.md\",\n         \"algorithms/pca.md\"]","category":"page"},{"location":"algorithms/api/","page":"API/Reference","title":"API/Reference","text":"ADI.ADIAlgorithm\nreconstruct\nsubtract\nprocess\nADI.fit\nADI.design\nADI.ADIDesign\nADI.LinearDesign","category":"page"},{"location":"algorithms/api/#ADI.ADIAlgorithm","page":"API/Reference","title":"ADI.ADIAlgorithm","text":"ADI.ADIAlgorithm\n\nThis abstract type is used for defining ADI algorithms. Algorithms are stateful objects that define the options for a given algorithm (e.g. the number of components used in PCA decomposition). The most direct usage of an algorithm is to use it to fit HCI data; that is, given a sample of pixels, apply the algorithm using the given options and return an object containing all the necessary information to reconstruct the input data.\n\nSee the extended help (??ADIAlgorithm) for interface details.\n\nExtended help\n\nInterface\n\nTo extend ADIAlgorithm you may implement the following\n\nADI.fit(::Alg, data::AbstractMatrix; kwargs...)\n\nFit the data (flattened into a matrix). To support RDI, ensure the ref keyword argument is usable (ref is also a flattened matrix). This is the only method you need to implement for a new ADIAlgorithm, along with a suitable ADIDesign.\n\nADI.jl automatically coaxes the cube input into a matrix for use with fit, appropriately handling the various geometries. When available, this input is a view, so if the algorithm requires dense arrays, make sure to call collect when appropriate. If a given algorithm doesn't support the default operations, all that needs to be done is override the default behavior (for an example, see the GreeDS implementation).\n\n\n\nreconstruct(::Alg, cube; kwargs...)\n\nFit the data using the algorithm and return a cube with the estimate of the PSF. By default uses the reconstruction from the ADIDesign fit to the data.\n\n\n\nsubtract(::Alg, cube; kwargs...)\n\nFit the data using the algorithm and return a cube that has had the PSF estimate subtracted. By default, calls reconstruct and subtracts it from cube.\n\n\n\nprocess(::ADIAlgorithm, cube; kwargs...)\n(::ADIAlgorithm)(cube; kwargs...)\n\nFully process the data (estimate, subtract, collapse). By default, derotates and collapses output from subtract. You only need to define process, since the functor version is supplied automatically.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/api/#ADI.reconstruct","page":"API/Reference","title":"ADI.reconstruct","text":"reconstruct(alg, cube; [ref], kwargs...)\n\nReconstruct the PSF approximation for the given algorithm, using ref as the reference cube if given and supported by the algorithm.\n\nExamples\n\njulia> cube, angles = # load data\n\njulia> S = reconstruct(PCA(10), cube);\n\njulia> size(S) == size(cube)\ntrue\n\njulia> flat_res = collapse(cube .- S, angles); # form resid, derotate, and combine\n\n\n\n\n\n","category":"function"},{"location":"algorithms/api/#ADI.subtract","page":"API/Reference","title":"ADI.subtract","text":"subtract(alg, cube; [ref], kwargs...)\n\nReconstruct the PSF approximation for the given algorithm and subtract it from cube, using ref as the reference cube if given and supported by the algorithm.\n\nExamples\n\njulia> cube, angles = # load data\n\njulia> R = subtract(PCA(10), cube);\n\njulia> size(R) == size(cube)\ntrue\n\njulia> flat_res = collapse(R, angles); # derotate, and combine\n\n\n\n\n\n","category":"function"},{"location":"algorithms/api/#ADI.process","page":"API/Reference","title":"ADI.process","text":"process(alg, cube, angles; [ref], kwargs...)\n\nFully process an ADI data cube using subtract and collapsing the residuals. Keyword arguments will be passed to ADI.fit.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/api/#ADI.fit","page":"API/Reference","title":"ADI.fit","text":"ADI.fit(::ADIAlgorithm, cube; [ref], kwargs...)\n\nGiven the description of an algorithm and the appropriate options, take the pixels from cube and fit them, returning an (ADIDesign) containing the necessary information from the fit (e.g. the principal components from PCA decomposition).\n\nIf the algorithm supports reference differential imaging (RDI), the reference cube can be passed by the keyword argument ref.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/api/#ADI.design","page":"API/Reference","title":"ADI.design","text":"ADI.design(::ADIDesign)\n\nReturn the pertinent data required to form the PSF approximation. For example, weights and components for PCA/NMF or the median frame for classic ADI.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/api/#ADI.ADIDesign","page":"API/Reference","title":"ADI.ADIDesign","text":"ADI.ADIDesign\n\nAn abstract type used for holding the output of ADI.fit. The purpose of these types is to hold the minimum information required to reconstruct the PSF estimate (e.g. weights and principal components from PCA). ADI.jl includes two designs- ADI.ClassicDesign and ADI.LinearDesign.\n\nInterface\n\nWhen implementing a new algorithm, if your outputs do not fit into either of those designs, you will have to create your own ADIDesign with the following methods-\n\nADI.design(::Design)\n\naccessor for the pertinent data to approximate the PSF\n\n\n\nreconstruct(::Design)\n\nreturn the approximate PSF estimate as a matrix\n\n\n\n\n\n","category":"type"},{"location":"algorithms/api/#ADI.LinearDesign","page":"API/Reference","title":"ADI.LinearDesign","text":"ADI.LinearDesign(basis, coeffs)\n\nA \"linear\" design implies the use of some linear basis for reconstructing data along with a set of coefficients or weights. The reconstruction will be the matrix product of the weights and the basis, w * Z. \n\nADI.design will return (basis, ceoffs), and you can also extract them via iteration, like Z, w = design.\n\n\n\n\n\n","category":"type"},{"location":"api/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"api/","page":"Index","title":"Index","text":"","category":"page"},{"location":"algorithms/greeds/#greeds","page":"GreeDS","title":"GreeDS","text":"","category":"section"},{"location":"algorithms/greeds/#API/Reference","page":"GreeDS","title":"API/Reference","text":"","category":"section"},{"location":"algorithms/greeds/","page":"GreeDS","title":"GreeDS","text":"GreeDS","category":"page"},{"location":"algorithms/greeds/#ADI.GreeDS","page":"GreeDS","title":"ADI.GreeDS","text":"GreeDS(alg=PCA(); threshold=0)\nGreeDS(ncomps; threshold=0, options...)\n\nPerforms the greedy disk subtraction (GreeDS) algorithm.\n\nThis method is an iterative approach to standard ADI reduction which seeks to minimize over-subtraction by constraining the low-rank matrix approximation from alg. By default, uses PCA. If ncomps or other PCA options are provided, they will be passed to the constructor.\n\nnote: Note\nThe GreeDS algorithm requires fully reconstructing a cube at each iteration, which requires knowing the geometry of the input (full-frame, annulus, etc.) and the corresponding parallactic angles. These angles must be passed as a keyword argument angles. In the case of reducing data, e.g. GreeDS()(cube, angles) the angles will be passed automatically. It is important to clarify, these angles should correspond to the reference data in the case of RDI, e.g. GreeDS()(cube, angles; ref=ref_cube, angles=ref_angles)\n\nAlgorithms\n\nThe following algorithms work natively with GreeDS: PCA, TPCA, and NMF\n\nReferences\n\nPairet et al. 2018 \"Reference-less algorithm for circumstellar disks imaging\"\nPairet et al. 2020 \"MAYONNAISE: a morphological components analysis pipeline for circumstellar disks and exoplanets imaging in the near infrared\"\n\n\n\n\n\n","category":"type"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"EditURL = \"https://github.com/JuliaHCI/ADI.jl/blob/master/examples/betapictoris.jl\"","category":"page"},{"location":"examples/betapictoris/#ADI-Reduction-of-\\beta-Pictoris","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"","category":"section"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"This example will walk through a full reduction and some analysis of beta Pictoris in order to show the basic usage of ADI.jl for high-contrast imaging. beta Pictoris is a known exoplanet host with many publications regarding the direct images of its substellar companion and circumstellar disk.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"What will not be covered in this example are the basics of Julia, the fine details of ADI post-processing, or any reference documentation.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"","category":"page"},{"location":"examples/betapictoris/#Setup","page":"ADI Reduction of beta Pictoris","title":"Setup","text":"","category":"section"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"Let's begin by importing the necessary libraries. You may need to add these packages if they are not already on your system.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"(@v1.5) pkg> add DataFrames HCIDatasets Plots PSFModels","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"In addition, a Project.toml file exists in the examples/ folder with the necessary dependencies. Start the REPL in the base ADI.jl folder, then from Pkg mode","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"(@v1.5) pkg> activate examples\n(examples) pkg> instantiate\njulia> include(\"examples/betapictoris.jl\")","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"using ADI\nusing DataFrames\nusing HCIDatasets: BetaPictoris\nusing Plots\n\n# set up plotting\nfunction imshow(img; kwargs...)\n    ylim = extrema(axes(img, 1))\n    xlim = extrema(axes(img, 2))\n    heatmap(axes(img)..., img; aspect_ratio=1, xlim=xlim, ylim=ylim, kwargs...)\nend;\nnothing #hide","category":"page"},{"location":"examples/betapictoris/#Data-Reduction","page":"ADI Reduction of beta Pictoris","title":"Data Reduction","text":"","category":"section"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"Here we load the data for beta Pictoris from NaCo at the VLT. You may be prompted to download the data; see HCIDatasets.jl for more details.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"cube, angles = BetaPictoris[:cube, :pa];\nnothing #hide","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"To reduce the data, we need an algorithm. In ADI.jl we currently have median subtraction, PCA, NMF, and fixed-point GreeDS. These algorithms are treated as \"objects\" in the sense that we initialize them with options and then pass them around inside the ADI.jl framework to retrieve the results we want.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"The usage for fitting the speckle estimate, projecting and subtracting this estimate from the target cube, and derotating and collapsing the residual all are encompassed by calling the algorithm as a function.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"alg = PCA(10) # 10 components\nreduced = alg(cube, angles)\nimshow(reduced)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"To try out different algorithms, all you should have to do is change one line and re-run the remaining code. Let's briefly explore a few different algorithms","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"algs = (alg, NMF(10), Classic(), GreeDS(10))\nreduced_frames = [alg(cube, angles) for alg in algs];\nnothing #hide","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"figs = (imshow(reduced, ticks=false) for reduced in reduced_frames)\nplot(\n    figs...,\n    title=[\"PCA(10)\" \"NMF(10)\" \"Classic(median)\" \"GreeDS(10)\"],\n    layout=(2, 2),\n    size=(900, 800),\n    dpi=75\n)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"You may want to mask out an interior angle since there is an inner limit for our signal to be a real planet (as opposed to systematics from the optical system or noise). We can mask out an interior circle either before processing with the algorithm or afterwards using HCIToolbox.mask_circle (note: HCIToolbox is re-exported by ADI.jl, so all its features are usable without importing it directly).","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"mask_cube = mask_circle(cube, 10)\nmask_reduced = alg(mask_cube, angles)\nimshow(mask_reduced)","category":"page"},{"location":"examples/betapictoris/#S/N-and-Significance-Maps","page":"ADI Reduction of beta Pictoris","title":"S/N and Significance Maps","text":"","category":"section"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"Now that we have our reduced frame, let's look at the signal-to-noise ratio (SNR, S/N). We use the exact S/N calculation here, implemented in a fast, multi-threaded framework using detectionmap. In order to measure the S/N, though, we need the effective FWHM of our instrument. Normally, we would measure this from an off-axis (or non-coronagraphic) PSF, but for simplicity I'll hard-code a value.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"fwhm = 4.6\nsnrmap = detectionmap(snr, reduced, fwhm)\nimshow(snrmap)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"If we want to get the statistical significance, we need to convert from the Student-t confidence interval derived in the S/N to the Gaussian significance. We can accomplish this by calling","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"sigmap = detectionmap(significance, reduced, fwhm)\nimshow(sigmap)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"Now, let's do some very basic frequentist planet detection by thresholding this significance","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"sigmap_cutoff = @. sigmap > 5\nimshow(sigmap_cutoff)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"looks like we've successfully pulled out the companion beta Pictoris b from the data!","category":"page"},{"location":"examples/betapictoris/#Contrast-Curve","page":"ADI Reduction of beta Pictoris","title":"Contrast Curve","text":"","category":"section"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"We are also interested in analyzing how the algorithm affects our data, especially calculating the throughput and the contrast curve. These measure, effectively, how much signal is lost during the subtraction step of the algorithm and give us an idea of what the limits of our algorithm are with our data.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"Before we move on, we need to create a PSF model for our data. PSFModels.jl contains some simple functional PSFs, or we can use an empirical PSF. We will use the empirical PSF provided by HCIDatasets for our calculations","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"using PSFModels\npsf = BetaPictoris[:psf] ./ maximum(BetaPictoris[:psf])\nkern_psf = PSFModels.Gaussian(fwhm);\nnothing #hide","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"plot(\n    imshow(psf),\n    plot(kern_psf, -19:19, -19:19),\n    layout=2,\n    size=(500, 250),\n    cbar=false,\n    ticks=false\n)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"and now we can calculate the 5σ contrast curve using contrast_curve. Contrast is defined by the ratio of astrophysical flux to Contrast is measured in comparison to the flux of the star; by default ADI.jl finds this flux by measuring the flux with a circular aperture in the central fwhm of the median-combined cube.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"cc = contrast_curve(alg, cube, angles, psf; fwhm=fwhm, nbranch=6) |> DataFrame\nfirst(filter(row -> isfinite(row.contrast_corr), cc), 5)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"and lets plot it","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"plot(\n    cc.distance,\n    [cc.contrast_corr cc.contrast],\n    yscale=:log10,\n    xlim=(0, NaN),\n    label=[\"Student-t\" \"Gaussian\"],\n    ylabel=\"5-sigma contrast\",\n    xlabel=\"radius [px]\"\n)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"You'll notice a pretty severe bump indicating poor contrast where the original companion is! Because this companion is very bright it will bias the contrast measurement.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"Typically you'd like to fit the companion signal and remove it in a maximum likelihood framework. For convenience here, let's use the :cube_empty entry for BetaPictoris, which already has the companion removed.","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"cube_empty = BetaPictoris[:cube_empty]\nreduced_empty = alg(cube_empty, angles)\nimshow(reduced_empty)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"cc_empty = contrast_curve(alg, cube_empty, angles, psf; fwhm=fwhm, nbranch=6) |> DataFrame\nfirst(filter(row -> isfinite(row.contrast_corr), cc_empty), 5)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"plot(\n    cc_empty.distance,\n    [cc_empty.contrast_corr cc_empty.contrast],\n    yscale=:log10,\n    xlim=(0, NaN),\n    label=[\"Student-t\" \"Gaussian\"],\n    ylabel=\"5-sigma contrast\",\n    xlabel=\"radius [px]\"\n)","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"","category":"page"},{"location":"examples/betapictoris/","page":"ADI Reduction of beta Pictoris","title":"ADI Reduction of beta Pictoris","text":"This page was generated using Literate.jl.","category":"page"},{"location":"framewise/#Framewise","page":"Framewise","title":"Framewise","text":"","category":"section"},{"location":"framewise/","page":"Framewise","title":"Framewise","text":"For an example of Framewise in use, along with spatial filtering, see this example.","category":"page"},{"location":"framewise/","page":"Framewise","title":"Framewise","text":"Framewise","category":"page"},{"location":"framewise/#ADI.Framewise","page":"Framewise","title":"ADI.Framewise","text":"Framewise(alg; limit=Inf, delta_rot=1)\nFramewise(algs::AbstractVector; limit=Inf, delta_rot=1)\n\nWrap an algorithm such that the underlying data will be processed frame by frame. For each frame a reference library is created from the data. This reference can be filtered by rejecting frames which have not rotated a sufficient parallactic angle. delta_rot sets the required arc length for rotation in units of the FWHM. The number of frames retained can be specified with limit, e.g. the 4 closest frames in time with the target frame.\n\nBecause the framewise application of an algorithm requires additional information, the following keyword arguments must be provided to reconstruct or subtract.\n\nfwhm - the FWHM of the instrument in pixels. Will be set to the width of a MultiAnnulusView\nangles - the measured parallactic angles for each frame\nr - The radius of the arc to calculate the parallactic angle threshold. Will be set automatically if using AnnulusView or MultiAnnulusView.\n\nIn addition, Framewise versions of algorithms do not implement ADI.fit and do not currently support RDI.\n\nAnnular reduction\n\nIn the case of reducing a MultiAnnulusView, a vector of algorithms can be used, each one corresponding to each annulus of the view. In this case, too, delta_rot can be given as a vector or as a tuple. If it is given as a tuple, delta_rot will increase linearly from the first value to the last value across each annulus.\n\nExamples\n\njulia> cube, angles = # load data\n\njulia> alg = PCA(10) # the algorithm to use on each reference\n\njulia> res = Framewise(alg)(cube, angles; r=10, fwhm=5);\n\njulia> mav = MultiAnnulusView(cube, 5; inner=5);\n\njulia> res_ann = Framewise(alg, delta_rot=(0.1, 1))(mav, angles);\n\n\n\n\n\n","category":"type"},{"location":"framewise/#API/Reference","page":"Framewise","title":"API/Reference","text":"","category":"section"},{"location":"framewise/","page":"Framewise","title":"Framewise","text":"AnnulusView\nMultiAnnulusView\neachannulus\ninverse\ninverse!","category":"page"},{"location":"framewise/#HCIToolbox.AnnulusView","page":"Framewise","title":"HCIToolbox.AnnulusView","text":"AnnulusView(cube::AbstractArray{T,3};\n            inner=0, outer=last(size(parent))/2 + 0.5,\n            fill=0)\n\nCut out an annulus with inner radius inner and outer radius outer. Values that fall outside of this region will be replaced with fill. This does not copy any data, it is merely a view into the data.\n\n\n\n\n\n(::AnnulusView)(asview=false)\n\nReturn the pixels that fall within the annulus as a matrix. This matrix is equivalent to unrolling each frame and then spatially filtering the pixels outside the annulus. If asview is true, the returned values will be a view of the parent array instead of a copy.\n\nExamples\n\njulia> ann = AnnulusView(ones(10, 101, 101); inner=5, outer=20);\n\njulia> X = ann();\n\njulia> size(X)\n(10, 1188)\n\n\n\n\n\n","category":"type"},{"location":"framewise/#HCIToolbox.MultiAnnulusView","page":"Framewise","title":"HCIToolbox.MultiAnnulusView","text":"MultiAnnulusView(cube::AbstractArray{T,3} width, radii; fill=0)\n\nCreate multiple annuli at each radius in radii with width width. Values that fall outside of these regions will be replaced with fill. This does not copy any data, it is merely a view into the data.\n\n\n\n\n\nMultiAnnulusView(cube::AbstractArray{T,3}, width;\n                 inner=0, outer=last(size(parent))/2 + 0.5,\n                 fill=0)\n\nCreate multiple annuli between inner and outer with width spacing. Values that fall outside of these regions will be replaced with fill. This does not copy any data, it is merely a view into the data.\n\n\n\n\n\n(::MultiAnnulusView)(idx, asview=false)\n\nReturn the idxth annulus as a matrix. This is equivalent to unrolling the frame and filtering out pixels outside of the idxth annulus. If asview is true, the returned values will be a view of the parent array instead of a copy.\n\nExamples\n\njulia> ann = MultiAnnulusView(ones(10, 101, 101), 5; inner=5, outer=30);\n\njulia> X = ann(1);\n\njulia> size(X)\n(10, 248)\n\njulia> X2 = ann(2);\n\njulia> size(X2)\n(10, 404)\n\nSee also\n\neachannulus\n\n\n\n\n\n","category":"type"},{"location":"framewise/#HCIToolbox.eachannulus","page":"Framewise","title":"HCIToolbox.eachannulus","text":"eachannulus(::MultiAnnulusView, asview=false)\n\nCreate a generator for each annulus in the view. If asview is true, the annuli will be returned as a view into the parent array instead of a copy.\n\nExamples\n\njulia> ann = MultiAnnulusView(ones(10, 101, 101), 5; inner=5, outer=30);\n\njulia> [size(X) for X in eachannulus(ann)]\n5-element Array{Tuple{Int64,Int64},1}:\n (10, 248)\n (10, 404)\n (10, 560)\n (10, 716)\n (10, 880)\n\n\n\n\n\n","category":"function"},{"location":"framewise/#HCIToolbox.inverse","page":"Framewise","title":"HCIToolbox.inverse","text":"inverse(::AnnulusView, mat::AbstractMatrix)\n\nGenerate a cube similar to the view with the pixels from mat. mat should have the same size as the matrix output from AnnulusView\n\nExamples\n\njulia> ann = AnnulusView(ones(10, 101, 101); inner=5, outer=20);\n\njulia> X = ann();\n\njulia> out = inverse(ann, -X);\n\njulia> out ≈ -ann\ntrue\n\n\n\n\n\ninverse(::MultiAnnulusView, idx, mat)\ninverse(::MultiAnnulusView, mats...)\n\nGenerate a cube similar to the view using the given pixel matrices. The pixels from mat will be put into the location of the idxth annulus. mat should have the same size as the output matrices generated by MultiAnnulusView. If multiple matrices are supplied, it is assumed each one corresponds to each annulus in the view.\n\nExamples\n\nExpand a single annulus-\n\njulia> ann = MultiAnnulusView(ones(10, 101, 101), 5; inner=5, outer=30);\n\njulia> X = ann(1);\n\njulia> out = inverse(ann, 1, -X);\n\njulia> sum(out) == -sum(X)\ntrue\n\nexpand many annuli-\n\njulia> Xs = [-X for X in eachannulus(ann)];\n\njulia> out = inverse(ann, Xs);\n\njulia> out ≈ -ann\ntrue\n\n\n\n\n\n","category":"function"},{"location":"framewise/#HCIToolbox.inverse!","page":"Framewise","title":"HCIToolbox.inverse!","text":"inverse!(::AnnulusView, out, mat)\n\nIn-place version of inverse that fills out in-place.\n\n\n\n\n\ninverse!(::MultiAnnulusView, out, idx, mat)\ninverse!(::MultiAnnulusView, out, mats...)\n\nIn-place version of inverse that fills out with annuli defined by the geometry of the view.\n\n\n\n\n\n","category":"function"},{"location":"metrics/#Metrics","page":"Metrics","title":"Metrics","text":"","category":"section"},{"location":"metrics/","page":"Metrics","title":"Metrics","text":"Modules = [ADI.Metrics]","category":"page"},{"location":"metrics/","page":"Metrics","title":"Metrics","text":"ADI.Metrics","category":"page"},{"location":"metrics/#ADI.Metrics","page":"Metrics","title":"ADI.Metrics","text":"ADI.Metrics\n\nThis module provides code for analyzing the results from ADI in a way that is interpretable statistically. Some of the key functionalities are signal-to-noise, significance, the receiver operating characteristic, and the contrast curve.\n\n\n\n\n\n","category":"module"},{"location":"metrics/#Detection-maps","page":"Metrics","title":"Detection maps","text":"","category":"section"},{"location":"metrics/","page":"Metrics","title":"Metrics","text":"detectionmap\nsnr\nsignificance\nnoise\nstimmap\nstim_threshold\nMetrics.stim","category":"page"},{"location":"metrics/#ADI.Metrics.detectionmap","page":"Metrics","title":"ADI.Metrics.detectionmap","text":"detectionmap([method=snr], data, fwhm; fill=0)\n\nParallel implementation of arbitrary detection mapping applied to each pixel in the input image. Any invalid values will be set to fill.\n\nThe following methods are provided in the Metrics module:\n\nsnr - signal-to-noise ratio (S/N) using student-t statistics to account for small sample penalty.\nsignificance - Gaussian signifance using student-t statistics to account for small samples penalty.\nnoise - Standard deviation of apertures in each annulus.\n\ntip: Tip\nThis code is automatically multi-threaded, so be sure to set JULIA_NUM_THREADS before loading your runtime to take advantage of it!\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.snr","page":"Metrics","title":"ADI.Metrics.snr","text":"snr(data, position, fwhm)\n\nCalculate the signal to noise ratio (SNR, S/N) for a test point at position using apertures of diameter fwhm in a residual frame.\n\nUses the method of Mawet et al. 2014 which includes penalties for small sample statistics. These are encoded by using a student's t-test for calculating the SNR.\n\nnote: Note\nSNR is not equivalent to significance, use significance instead\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.significance","page":"Metrics","title":"ADI.Metrics.significance","text":"significance(data, position, fwhm)\n\nCalculates the Gaussian significance from the signal-to-noise ratio (SNR, S/N) for a test point at position using apertures of diameter fwhm in a residual frame.\n\nThe Gaussian signifiance is calculated from converting the SNR confidence limit from a student t distribution to a Gaussian via\n\ntextsig(textSNR) = Phi^-1leftint_0^textSNRt_nu(x)dxright\n\nwhere the degrees of freedom nu is given as 2pi r  Gamma - 2 where r is the radial distance of each pixel from the center of the frame.\n\nSee Also\n\nsnr\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.noise","page":"Metrics","title":"ADI.Metrics.noise","text":"noise(data, position, fwhm)\n\nCalculate the statistical noise for a test point at position using apertures of diameter fwhm in a residual frame.\n\nUses the standard deviation of the apertures in the entire annulus. This is distinct from the snr noise calculation, which defines a confidence interval using student-t statistics. This means you cannot simply create a noise map and divide it from the signal to create an equivalent S/N map.\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.stimmap","page":"Metrics","title":"ADI.Metrics.stimmap","text":"stimmap(residuals, angles)\n\nCalculate the standardized trajectory intensity mean (STIM) map. The inputs are a cube of residuals and the corresponding parallactic angles.\n\nThis method seeks to improve upon the typical student-t S/N tests (snr, significance) by calculating statistics in the temporal domain instead of the spatial domain. This is why the full residual cube is required rather than a reduced frame. \n\nIn particular, the STIM map is robust to detections with multiple objects or extended sources within the same annuli, which results in very high noise estimates using spatial methods. The STIM map also performs better at small angular separations, since the temporal domain has no limitations from limited resolution elements.\n\nPairet et al. 2019 derives a detection threshold of τ = 0.5 for the STIM map. The detection threshold can be calculated for a specific dataset using stim_threshold.\n\nExamples\n\njulia> cube, angles = # load data\n\njulia> S = subtract(PCA(10), cube, angles);\n\njulia> sm = stimmap(S, angles);\n\nReferences\n\nPairet et al. 2019 \"STIM map: detection map for exoplanets imaging beyond asymptotic Gaussian residual speckle noise\"\n\nSee Also\n\nstim_threshold\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.stim_threshold","page":"Metrics","title":"ADI.Metrics.stim_threshold","text":"stim_threshold([stimmap, ] residuals, angles)\n\nCalculate the detection threshold for the standardized trajectory intensity mean (STIM) map. This method uses the same residual cube as stimmap but adds an additional step of estimating the residual noise by derotating the residuals with the opposite parallactic angles.\n\nIf the STIM map has already been calculated, it can be passed in, otherwise it will be calculated in addition to the noise map. Note this will not return the STIM map, only the threshold.\n\nThe threshold is derived in section 5.1 of Pairet et al. 2019 as the ratio of the number of pixels above the approximated noise map. They found a value of τ = 0.5 to be typical.\n\nExamples\n\njulia> cube, angles = # load data\n\njulia> S = subtract(PCA(10), cube, angles);\n\njulia> sm = stimmap(S, angles);\n\njulia> τ = stim_threshold(sm, S, angles);\n\nReferences\n\nPairet et al. 2019 \"STIM map: detection map for exoplanets imaging beyond asymptotic Gaussian residual speckle noise\"\n\nSee Also\n\nstimmap\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.stim","page":"Metrics","title":"ADI.Metrics.stim","text":"Metrics.stim(cube; dims)\n\nCalculates the STIM map of a derotated cube along the given dims. dims should correspond to the temporal axis of the cube. The STIM statistic is the slice mean divided by the slice standard deviation. Invalid values will become 0.\n\n\n\n\n\n","category":"function"},{"location":"metrics/#Ensemble-methods","page":"Metrics","title":"Ensemble methods","text":"","category":"section"},{"location":"metrics/","page":"Metrics","title":"Metrics","text":"The following methods utilize the results of multiple ADI reductions, in some form.","category":"page"},{"location":"metrics/","page":"Metrics","title":"Metrics","text":"slimmap","category":"page"},{"location":"metrics/#ADI.Metrics.slimmap","page":"Metrics","title":"ADI.Metrics.slimmap","text":"slimmap(residuals, angles; N)\nslimmap(stim_maps; N)\n\nCalculate the STIM largest intensity mask (SLIMask) map. This is an ensemble method which averages the STIM maps for multiple residual cubes. In addition to computing this average, for each STIM map all but the brightest N pixels will be masked out and eventaully averaged to create the SLIMask.\n\nN should represent a cutoff for the number of expected companions. For example, if the FWHM of the companion signal is 5 pixels, then the area under the fwhm is ~20 pixels. If I want to probe the brightest 4 potential companions, I would mask all but the N = 20 * 4 = 80 brightest pixels.\n\nBoth the average STIM map and the SLIMask will be returned, and the two can be multiplied together to produce the SLIMask-STIM map. This achieves two things: first, the masking makes most of the pixels 0, providing better visual contrast in the map, and second, by averaging the mask, pixels which are not consistently in the brightest N for each STIM map will have lower probabilities in the corresponding SLIMask-STIM map.\n\nExamples\n\nThis example recreates the analysis shown in Pairet, B. (2020) where the SLIM map is computed with the ensemble of residual cubes produced by increasing ranks of PCA subtraction.\n\njulia> cube, angles = # load data\n\njulia> algs = PCA.(5:25);\n\njulia> residual_cubes = subtract.(algs, Ref(cube));\n\njulia> stim_av, slimmask = slimmap(residual_cubes, angles; N=100);\n\njulia> slim_prob_map = stim_av .* slimmask;\n\nReferences\n\nPairet, B. 2020 \"Signal processing methods for high-contrast observations of planetary systems\"\n\nSee also\n\nstimmap, stim\n\n\n\n\n\n","category":"function"},{"location":"metrics/#Throughput","page":"Metrics","title":"Throughput","text":"","category":"section"},{"location":"metrics/","page":"Metrics","title":"Metrics","text":"throughput","category":"page"},{"location":"metrics/#ADI.Metrics.throughput","page":"Metrics","title":"ADI.Metrics.throughput","text":"throughput(alg, cube, angles, psf;\n           fwhm, nbranch=1, theta=0, inner_rad=1,\n           fc_rad_sep=3, snr=100, kwargs...)\n\nCalculate the throughput of alg by injecting fake companions into cube and measuring the relative photometry of each companion in the reduced frame. The photometry is measured using a circular aperture with a diameter matching the fwhm. Any additional kwargs will be passed to alg when it is called.\n\nKeyword Arguments\n\nnbranch - number of azimuthal branches to use\ntheta - position angle of initial branch\ninner_rad - position of innermost planet in FWHM\nfc_rad_sep - the separation between planets in FWHM for a single reduction\nsnr - the target signal to noise ratio of the injected planets\nreduced_empty - the collapsed residual frame for estimating the noise. Will process using alg if not provided.\n\n\n\n\n\nthroughput(alg, cube, angles, psf, position;\n           fwhm, snr=100, reduced_empty=nothing,\n           verbose=true, kwargs...)\n\nCalculate the throughput of alg by injecting psf into cube at the given position and measuring the relative photometry of the companion in the reduced frame. The photometry is measured using a circular aperture with a diameter matching the fwhm. Any additional kwargs will be passed to alg when it is called.\n\nIf position is a tuple or a vector, it will be parsed as the cartesian coordinate (x, y). If position is a CoordinateTransformations.Polar it will be parsed as polar coordinates from the center of the cube. Note the Polar type expects angles in radians.\n\nKeyword Arguments\n\nfwhm - the full width at half-maximum\nsnr - the target signal to noise ratio of the injected planets\nreduced_empty - the collapsed residual frame for estimating the noise. Will process using alg if not provided.\nverbose - show informative messages during process\n\n\n\n\n\n","category":"function"},{"location":"metrics/#Contrast-curve","page":"Metrics","title":"Contrast curve","text":"","category":"section"},{"location":"metrics/","page":"Metrics","title":"Metrics","text":"contrast_curve\nMetrics.subsample_contrast\nMetrics.estimate_starphot","category":"page"},{"location":"metrics/#ADI.Metrics.contrast_curve","page":"Metrics","title":"ADI.Metrics.contrast_curve","text":"contrast_curve(alg, cube, angles, psf;\n               fwhm, sigma=5, nbranch=1, theta=0, inner_rad=1,\n               starphot=Metrics.estimate_starphot(cube, fwhm),\n               fc_rad_sep=3, snr=100, k=2, smooth=true,\n               subsample=true, kwargs...)\n\nCalculate the throughput-calibrated contrast. This first processes the algorithmic throughput by injecting instances of psf into cube. These are processed through alg and the ratio of the recovered flux to the injected flux is calculated. These companions are injected in resolution elements across the frame, which can be changed via the various keyword arguments.\n\nThe throughput can only be calculated for discrete resolution elements, but we typically want a much smoother curve. To accomplish this, we measure the noise (the standard deviation of all resolution elements in an annulus at a given radius) for every pixel in increasing radii. We then interpolate the throughput to this grid and return the subsampled curves.\n\nReturned Fields\n\ndistance - The radial distance (in pixels) for each measurement\ncontrast - The Gaussian sensitivity\ncontrast_corr - The Student-t sensitivity\nnoise - The noise measured for each distance\nthroughput - The throughput measured for each distance.\n\nKeyword Arguments\n\nsigma - The confidence limit in terms of Gaussian standard deviations\nstarphot - The flux of the star. By default calculates the flux in the central core.\n\nInjection Options (See also throughput)\n\nnbranch - number of azimuthal branches to use\ntheta - position angle of initial branch\ninner_rad - position of innermost planet in FWHM\nfc_rad_sep - the separation between planets in FWHM for a single reduction\nsnr - the target signal to noise ratio of the injected planets\n\nSubsampling Options (See also Metrics.subsample_contrast)\n\nsubsample - If true, subsamples the throughput measurements to increase density of curve\nk - The order of the BSpline used for subsampling the throughput\nsmooth - If true, will smooth the subsampled noise measurements with a 2nd order Savitzky-Golay filter\n\nAny additional kwargs will be passed to alg when it is called.\n\ntip: Tip\nIf you prefer a tabular format, simply pipe the output of this function into any type supporting the Tables.jl interface, e.g.contrast_curve(alg, cube, angles, psf; fwhm=fwhm) |> DataFrame\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.subsample_contrast","page":"Metrics","title":"ADI.Metrics.subsample_contrast","text":"Metrics.subsample_contrast(empty_frame, distance, throughput;\n                           fwhm, starphot, sigma=5, inner_rad=1,\n                           theta=0, smooth=true, k=2)\n\nHelper function to subsample and smooth a contrast curve.\n\nContrast curves, by definition, are calculated with discrete resolution elements. This can cause contrast curves to have very few points instead of appearing as a continuously measured statistic across the pixels. We alleviate this by sub-sampling the throughput (via BSpline interpolation) across each pixel (instead of each resolution element).\n\nThe noise can be found efficiently enough, so rather than interpolate we measure the noise in annuli of width fwhm increasing in distance by 1 pixel. We measure this noise in empty_frame, which should be a 2D reduced ADI frame.\n\nThe noise measurements can be noisy, so a 2nd order Savitzky-Golay filter can be applied via smooth. This fits a quadratic polynomial over a window of fwhm/2 points together to reduce high-frequency jitter.\n\nExamples\n\nHere is an example which calculates the exact contrast curve in addition to a subsampled curve without re-calculating the throughput.\n\ncube, angles, psf = # load data\n\nalg = PCA(10)\ncc = contrast_curve(alg, cube, angles, psf; fwhm=8.4, subsample=false)\nreduced_empty = alg(cube, angles)\nsp = Metrics.estimate_starphot(cube, 8.4)\ncc_sub = Metrics.subsample_contrast(reduced_empty, cc.distance, cc.throughput;\n                                    fwhm=8.4, starphot=sp)\n\n\n\n\n\n","category":"function"},{"location":"metrics/#ADI.Metrics.estimate_starphot","page":"Metrics","title":"ADI.Metrics.estimate_starphot","text":"Metrics.estimate_starphot(cube, fwhm)\nMetrics.estimate_starphot(frame, fwhm)\n\nSimple utility to estimate the stellar photometry by placing a circular aperture with fwhm diameter in the center of the frame. If a cube is provided, first the median frame will be found.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/classic/#classic","page":"Classic","title":"Classic","text":"","category":"section"},{"location":"algorithms/classic/#API/Reference","page":"Classic","title":"API/Reference","text":"","category":"section"},{"location":"algorithms/classic/","page":"Classic","title":"Classic","text":"Classic\nADI.ClassicDesign","category":"page"},{"location":"algorithms/classic/#ADI.Classic","page":"Classic","title":"ADI.Classic","text":"Classic(;method=median)\nClassic(method)\n\nClassic PSF subtraction using the median of entire data cube. If another statistic is desired, like the mean, it can be passed as an argument as long as it supports slicing multi-dimensional arrays.\n\nReferences\n\nMarois et al. 2006 Angular Differential Imaging: A Powerful High-Contrast Imaging Technique\n\n\n\n\n\n","category":"type"},{"location":"algorithms/classic/#ADI.ClassicDesign","page":"Classic","title":"ADI.ClassicDesign","text":"ADI.ClassicDesign(n, frame)\n\nOutput for the Classic algorithm which contains the static frame unrolled into a vector (with size (1, Npx)). reconstruct will tile this vector in a non-allocating way n times to appear like a flattened cube. ADI.design will return the static frame .\n\n\n\n\n\n","category":"type"},{"location":"introduction/#Introduction-to-High-Contrast-Imaging","page":"Introduction to HCI","title":"Introduction to High-Contrast Imaging","text":"","category":"section"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"This will serve as a brief primer to high-contrast imaging (HCI) to illustrate the concepts and themes prevalent within this package. This is not meant to be an exhaustive lecture note on the topic, but more of a gentle introduction.","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"If you are comfortable with HCI topics, consider skipping to the Getting Started section to get introduced to ADI.jl, browse the Examples to see sample workflows, or browse through the API to start exploring the capabilities of ADI.jl.","category":"page"},{"location":"introduction/#What-is-HCI","page":"Introduction to HCI","title":"What is HCI","text":"","category":"section"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"HCI is an advanced imaging technique comprising modern instrumentation, clever observational techniques, and post-processing algorithms. The goal of HCI is to probe the circumstellar regions of a star in the search for companions, debris disks, and more. The use of large aperture telescopes, adaptive optics (AO), and coronagraphs are the basis of HCI. An example of an image taken with these instruments is shown below.","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"(Image: )","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"What is notable in this image is that there is a lot of structured noise in the image that is overwhelming any potential companion signal. The center of the image is particularly noisy, which is precisely where we are most interested in searching for exoplanets. This noise is the effect of quasi-static speckles in the focal-plane. These speckles occur from non-common path aberrations in the AO system and are a fundamental part of the data received by these instruments. Improving the quality of instrumentation is an active topic of HCI research, but it is beyond the scope of this introduction.","category":"page"},{"location":"introduction/#adi","page":"Introduction to HCI","title":"Angular Differential Imaging (ADI)","text":"","category":"section"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"Because this noise is fundamental to the data, post-processing must be performed in order to see any circumstellar signal. This post-processing requires us to fit the PSF of the speckles and then remove it. An example of the above frame with the speckles removed is shown below.","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"(Image: )","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"Unfortunately, there is no companion evident; but the speckles have been removed, so what is left? The exoplanet is still sitting below the statistical noise in this frame, but the noise can be averaged out by combining many frames together. Since we are concerned with subtracting the speckles, we need to be careful and consider how do we fit and subtract the speckles without removing potential companion signal?","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"This is where angular differential imaging (ADI) comes in. ADI is an observational technique pioneered in the early 2000s as an extension of roll deconvolution for ground-based telescopes. The core of this process is that the quasi-static speckles are a function of the optical system, not the astrophysical source. Throughout a night of observing we can leverage the rotation of the Earth to make the field-of-view (FOV) appear to rotate (on an Alt-Az mounted telescope with the field rotator disabled). Even though the sky appears to rotate, because the speckles are due to the telescope optics they will not appear to rotate. The animation below shows a cube of data with a bright fake companion that illustrates the sky rotation typical of ADI.","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"(Image: )","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"By taking this sequence of images (commonly referred to as a cube) we can more easily model and fit the speckle signal separate from any companions. If you median combine the cube as-is, the non-stationary companion signal will attenuate leaving just the speckles. If we derotate the sequence according to the parallactic angles for each frame we align the sky to a common heading. Now we can collapse the derotated sequence and the planet will constructively interfere while the now-rotating speckles will attenuate. The figure below shows these two competing reductions.","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"(Image: )","category":"page"},{"location":"introduction/#Post-Processing-Algorithms","page":"Introduction to HCI","title":"Post-Processing Algorithms","text":"","category":"section"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"Using data cubes (as described in the ADI section), we are tasked with fitting the speckles without capturing the rotating companion signal. Quite a few algorithms have been proposed and a thorough discussion of them is beyond the scope of this introduction. For now, let's assume the algorithms are a black-box that produce speckle approximation cubes.","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"If we have this cube, all we need to post-process the data is","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"Retrieve a speckle estimate cube\nSubtract the speckle estimate from the target cube and form a residual cube\nDerotate the residual cube according to the parallactic angles of the target\nCollapse the derotated residual cube","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"Steps 2-4 are shown in the following figure","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"(Image: )","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"After all this processing, finally the substellar companion HR8799e is evident. Hopefully this shows the difficulty of HCI and builds up part of the process that occurs outside of the reduction you'll be doing with ADI.jl.","category":"page"},{"location":"introduction/#References","page":"Introduction to HCI","title":"References","text":"","category":"section"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"Here is a selection of further reading for information about high-contrast imaging, ADI, and similar techniques","category":"page"},{"location":"introduction/","page":"Introduction to HCI","title":"Introduction to HCI","text":"Traub, Oppenheimer 2010, \"Direct Imaging of Exoplanets\"\nBowler 2016, \"Imaging Extrasolar Giant Planets\"\nPueyo 2018, \"Direct Imaging as a Detection Technique for Exoplanets\"\nMarois et al. 2006, \"Angular Differential Imaging: A Powerful High-Contrast Imaging Technique\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = ADI","category":"page"},{"location":"#ADI.jl","page":"Home","title":"ADI.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: GitHub) (Image: Build Status) (Image: Coverage) (Image: License)","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: JOSS) (Image: DOI)","category":"page"},{"location":"","page":"Home","title":"Home","text":"A package for angular differential imaging (ADI) along with its variants, such as reference differential imaging (RDI) and spectral differential imaging (SDI).","category":"page"},{"location":"#Installation-and-Setup","page":"Home","title":"Installation and Setup","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ADI.jl is a registered package and can be installed using the Julia package manager. From the Julia REPL, enter Pkg mode (by pressing ])","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia>]\n\n(@v1.5) pkg> add ADI","category":"page"},{"location":"","page":"Home","title":"Home","text":"To exit Pkg mode, just backspace. Once the package is installed it can be imported with","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using ADI","category":"page"},{"location":"","page":"Home","title":"Home","text":"For more information, see the Pkg documentation.","category":"page"},{"location":"#Citations","page":"Home","title":"Citations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use ADI.jl or derivates in your work, please consider citing both the JOSS paper and the code record. The JOSS paper citation can be found in CITATION.bib. The code will have a unique reference for each released version, so visit the zenodo record to grab the BibTeX for whichever version you used.","category":"page"},{"location":"#Contributing-and-Support","page":"Home","title":"Contributing and Support","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: ColPrac: Contributor's Guide on Collaborative Practices for Community Packages)","category":"page"},{"location":"","page":"Home","title":"Home","text":"In general contributions should follow ColPrac. Feel free to open an issue or reach out to the developers to coordinate a contribution or discuss ideas. For support with using ADI.jl, please open an issue describing the problem and steps to reproduce it.","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This work is distributed under the MIT \"expat\" license. See LICENSE for more information.","category":"page"}]
}
